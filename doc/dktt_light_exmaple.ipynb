{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dktt_light_exmaple.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD7GPfYWG3Z4"
      },
      "source": [
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "BASE_DIR = '/content/dirve'"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQrE63uxHDcb",
        "outputId": "7a29a6c6-c26f-4102-8115-ac7610711db7"
      },
      "source": [
        "# check if GPU is visible\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35GfjrIhHNcr",
        "outputId": "6e2134bc-1d01-4d24-ca7d-2f672a1f6e27"
      },
      "source": [
        "# mount google drive to access data\n",
        "drive.mount(BASE_DIR, force_remount=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/dirve\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK15nFpeHTC6"
      },
      "source": [
        "# change to the destination dir\n",
        "os.chdir(os.path.join(BASE_DIR, 'MyDrive', 'dktt_light', 'dktt_light'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da9U9NWJIRDJ",
        "outputId": "11a0aa71-ef67-4eff-97e0-d6c9055c2312"
      },
      "source": [
        "!pip install -r ../requirements.txt"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: absl-py==0.12.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 1)) (0.12.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 2)) (1.6.3)\n",
            "Requirement already satisfied: attrs==20.3.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 3)) (20.3.0)\n",
            "Requirement already satisfied: cachetools==4.2.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 4)) (4.2.1)\n",
            "Requirement already satisfied: certifi==2020.12.5 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 5)) (2020.12.5)\n",
            "Requirement already satisfied: cffi==1.14.5 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 6)) (1.14.5)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 8)) (0.10.0)\n",
            "Requirement already satisfied: Cython==0.29.22 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 9)) (0.29.22)\n",
            "Requirement already satisfied: dataclasses==0.6 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 10)) (0.6)\n",
            "Requirement already satisfied: dill==0.3.3 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 11)) (0.3.3)\n",
            "Requirement already satisfied: dm-tree==0.1.5 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 12)) (0.1.5)\n",
            "Requirement already satisfied: flatbuffers==1.12 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 13)) (1.12)\n",
            "Requirement already satisfied: future==0.18.2 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 14)) (0.18.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 15)) (0.3.3)\n",
            "Requirement already satisfied: gin-config==0.4.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 16)) (0.4.0)\n",
            "Requirement already satisfied: google-api-core==1.26.3 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 17)) (1.26.3)\n",
            "Requirement already satisfied: google-api-python-client==2.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 18)) (2.1.0)\n",
            "Requirement already satisfied: google-auth==1.28.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 19)) (1.28.0)\n",
            "Requirement already satisfied: google-auth-httplib2==0.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 20)) (0.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib==0.4.4 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 21)) (0.4.4)\n",
            "Requirement already satisfied: google-cloud-bigquery==2.13.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 22)) (2.13.1)\n",
            "Requirement already satisfied: google-cloud-core==1.6.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 23)) (1.6.0)\n",
            "Requirement already satisfied: google-crc32c==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 24)) (1.1.2)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 25)) (0.2.0)\n",
            "Requirement already satisfied: google-resumable-media==1.2.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 26)) (1.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos==1.53.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 27)) (1.53.0)\n",
            "Requirement already satisfied: grpcio==1.32.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 28)) (1.32.0)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 29)) (2.10.0)\n",
            "Requirement already satisfied: httplib2==0.19.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 30)) (0.19.1)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 31)) (2.10)\n",
            "Requirement already satisfied: importlib-metadata==3.10.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 32)) (3.10.0)\n",
            "Requirement already satisfied: importlib-resources==5.1.2 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 33)) (5.1.2)\n",
            "Requirement already satisfied: joblib==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 34)) (1.0.1)\n",
            "Requirement already satisfied: kaggle==1.5.12 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 35)) (1.5.12)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 36)) (1.1.2)\n",
            "Requirement already satisfied: kiwisolver==1.3.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 37)) (1.3.1)\n",
            "Requirement already satisfied: Markdown==3.3.4 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 38)) (3.3.4)\n",
            "Requirement already satisfied: matplotlib==3.4.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 39)) (3.4.1)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 40)) (1.19.5)\n",
            "Requirement already satisfied: oauth2client==4.1.3 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 41)) (4.1.3)\n",
            "Requirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 42)) (3.1.0)\n",
            "Requirement already satisfied: opencv-python-headless==4.5.1.48 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 43)) (4.5.1.48)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 44)) (3.3.0)\n",
            "Requirement already satisfied: packaging==20.9 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 45)) (20.9)\n",
            "Requirement already satisfied: pandas==1.2.3 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 46)) (1.2.3)\n",
            "Requirement already satisfied: Pillow==8.2.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 47)) (8.2.0)\n",
            "Requirement already satisfied: promise==2.3 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 48)) (2.3)\n",
            "Requirement already satisfied: proto-plus==1.18.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 49)) (1.18.1)\n",
            "Requirement already satisfied: protobuf==3.15.7 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 50)) (3.15.7)\n",
            "Requirement already satisfied: psutil==5.8.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 51)) (5.8.0)\n",
            "Requirement already satisfied: py-cpuinfo==7.0.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 52)) (7.0.0)\n",
            "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 53)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 54)) (0.2.8)\n",
            "Requirement already satisfied: pycocotools==2.0.2 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 55)) (2.0.2)\n",
            "Requirement already satisfied: pycparser==2.20 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 56)) (2.20)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 57)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 58)) (2.8.1)\n",
            "Requirement already satisfied: python-slugify==4.0.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 59)) (4.0.1)\n",
            "Requirement already satisfied: pytz==2021.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 60)) (2021.1)\n",
            "Requirement already satisfied: PyYAML==5.4.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 61)) (5.4.1)\n",
            "Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 62)) (2.25.1)\n",
            "Requirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 63)) (1.3.0)\n",
            "Requirement already satisfied: rsa==4.7.2 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 64)) (4.7.2)\n",
            "Requirement already satisfied: scikit-learn==0.24.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 65)) (0.24.1)\n",
            "Requirement already satisfied: scipy==1.6.2 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 66)) (1.6.2)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 67)) (0.1.95)\n",
            "Requirement already satisfied: seqeval==1.2.2 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 68)) (1.2.2)\n",
            "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 69)) (1.15.0)\n",
            "Requirement already satisfied: tensorboard==2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 70)) (2.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 71)) (1.8.0)\n",
            "Requirement already satisfied: tensorflow==2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 72)) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-addons==0.12.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 73)) (0.12.1)\n",
            "Requirement already satisfied: tensorflow-datasets==4.2.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 74)) (4.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator==2.4.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 75)) (2.4.0)\n",
            "Requirement already satisfied: tensorflow-hub==0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 76)) (0.11.0)\n",
            "Requirement already satisfied: tensorflow-metadata==0.29.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 77)) (0.29.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization==0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 78)) (0.5.0)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 79)) (1.1.0)\n",
            "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 80)) (1.3)\n",
            "Requirement already satisfied: tf-models-official==2.4.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 81)) (2.4.0)\n",
            "Requirement already satisfied: tf-slim==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 82)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl==2.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 83)) (2.1.0)\n",
            "Requirement already satisfied: tqdm==4.60.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 84)) (4.60.0)\n",
            "Requirement already satisfied: typeguard==2.12.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 85)) (2.12.0)\n",
            "Requirement already satisfied: typing-extensions==3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 86)) (3.7.4.3)\n",
            "Requirement already satisfied: uritemplate==3.0.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 87)) (3.0.1)\n",
            "Requirement already satisfied: urllib3==1.26.4 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 88)) (1.26.4)\n",
            "Requirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 89)) (1.0.1)\n",
            "Requirement already satisfied: wrapt==1.12.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 90)) (1.12.1)\n",
            "Requirement already satisfied: zipp==3.4.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 91)) (3.4.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse==1.6.3->-r ../requirements.txt (line 2)) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.26.3->-r ../requirements.txt (line 17)) (54.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dmLUFGGHxva",
        "outputId": "ace61c81-2e19-4727-960c-1b3971cb26f7"
      },
      "source": [
        "# to use default (optimal configuration), only adjust the dataset and single_attempts_only configuration\n",
        "!python main.py --dataset 'stat2011'"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 03:00:55.163428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "model params are {'params': {'hidden_size': 32, 'confidence': 4, 'temperature': 0.5, 'time_unit': 1, 'layer_postprocess_dropout': 0.15, 'relu_dropout': 0.15, 'attention_dropout': 0.15, 'num_heads': 8, 'shared_weights': False, 'filter_size': 64, 'kernal_size': 16, 'mask_out': 'future', 'num_encoder_blocks': 2, 'num_decoder_blocks': 0, 'q_matrix_trainable': False, 'item_difficulty': False}}\n",
            "fit params are {'batch_size': 128, 'epochs': 50, 'validation_split': 0.1}\n",
            "optimizer params = {'initial_learning_rate': 0.001, 'decay_steps': 100, 'decay_rate': 1.0, 'staircase': True}\n",
            "loss params = {'smoothing': 0.1}\n",
            "\n",
            " cv 0 starts for stat2011\n",
            "\n",
            "train data in /content/dirve/My Drive/dktt_light/data/stat2011-cv-train-0.csv is loaded\n",
            "test data in /content/dirve/My Drive/dktt_light/data/stat2011-cv-test-0.csv is loaded\n",
            "dataset = stat2011\n",
            "num of attempts = 189.62 K\n",
            "num of students = 333\n",
            "num of skills = 1224\n",
            "num of items = 1224\n",
            "problem and skill encoders are created\n",
            "train and test data are cleaned\n",
            "train and test sequences are extracted\n",
            "100% 266/266 [00:00<00:00, 12791.32it/s]\n",
            "100% 67/67 [00:00<00:00, 16413.67it/s]\n",
            "train and test sequences are folded\n",
            "train and test inputs and targets are created\n",
            "problem skill mapping is created\n",
            "2021-04-08 03:01:08.399879: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-08 03:01:08.400787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-08 03:01:08.405048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:01:08.405626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-04-08 03:01:08.405659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-08 03:01:08.407688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-08 03:01:08.407767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-04-08 03:01:08.409388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-08 03:01:08.409809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-08 03:01:08.411425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-08 03:01:08.411920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-04-08 03:01:08.412129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-04-08 03:01:08.412232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:01:08.412830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:01:08.413374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-08 03:01:08.413767: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-08 03:01:08.413879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:01:08.414409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-04-08 03:01:08.414445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-08 03:01:08.414481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-08 03:01:08.414504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-04-08 03:01:08.414525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-08 03:01:08.414545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-08 03:01:08.414568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-08 03:01:08.414587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-04-08 03:01:08.414607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-04-08 03:01:08.414686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:01:08.415241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:01:08.415758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-08 03:01:08.415835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-08 03:01:08.883472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-08 03:01:08.883520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-04-08 03:01:08.883532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-04-08 03:01:08.883805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:01:08.884434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:01:08.885037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:01:08.885554: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-08 03:01:08.885603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "model is created\n",
            "model is compiled\n",
            "start fitting\n",
            "2021-04-08 03:01:08.998359: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-04-08 03:01:08.998768: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /content/dirve/My Drive/dktt_light/dktt_light/model.py:198: DenseEinsum.__init__ (from official.nlp.modeling.layers.dense_einsum) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "DenseEinsum is deprecated. Please use tf.keras.experimental.EinsumDense layer instead.\n",
            "2021-04-08 03:01:12.160341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-08 03:01:12.384409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "10/10 [==============================] - 5s 126ms/step - loss: 0.8537 - val_loss: 0.6530\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6600 - val_loss: 0.5067\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5369 - val_loss: 0.4189\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4530 - val_loss: 0.3678\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4016 - val_loss: 0.3371\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3636 - val_loss: 0.3174\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3377 - val_loss: 0.3042\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3195 - val_loss: 0.2951\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3032 - val_loss: 0.2887\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2952 - val_loss: 0.2839\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2858 - val_loss: 0.2803\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2809 - val_loss: 0.2775\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2776 - val_loss: 0.2753\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2740 - val_loss: 0.2734\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2702 - val_loss: 0.2720\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2694 - val_loss: 0.2706\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2683 - val_loss: 0.2695\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2663 - val_loss: 0.2684\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2630 - val_loss: 0.2676\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2610 - val_loss: 0.2667\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2586 - val_loss: 0.2660\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2599 - val_loss: 0.2652\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2587 - val_loss: 0.2647\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2572 - val_loss: 0.2642\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2553 - val_loss: 0.2635\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2566 - val_loss: 0.2630\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2536 - val_loss: 0.2625\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2558 - val_loss: 0.2621\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2555 - val_loss: 0.2618\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2538 - val_loss: 0.2614\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2525 - val_loss: 0.2611\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2519 - val_loss: 0.2608\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2524 - val_loss: 0.2606\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2531 - val_loss: 0.2604\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2495 - val_loss: 0.2600\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2497 - val_loss: 0.2599\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2505 - val_loss: 0.2597\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2482 - val_loss: 0.2595\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2477 - val_loss: 0.2592\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2504 - val_loss: 0.2590\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2471 - val_loss: 0.2587\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2472 - val_loss: 0.2586\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2452 - val_loss: 0.2584\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2489 - val_loss: 0.2583\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2471 - val_loss: 0.2584\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2482 - val_loss: 0.2582\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2461 - val_loss: 0.2581\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2471 - val_loss: 0.2580\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2460 - val_loss: 0.2580\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2443 - val_loss: 0.2579\n",
            "test auc = 0.9519709179497655 in cv = 0\n",
            "\n",
            " cv 0 finished for stat2011\n",
            "\n",
            "\n",
            " cv 1 starts for stat2011\n",
            "\n",
            "train data in /content/dirve/My Drive/dktt_light/data/stat2011-cv-train-1.csv is loaded\n",
            "test data in /content/dirve/My Drive/dktt_light/data/stat2011-cv-test-1.csv is loaded\n",
            "problem and skill encoders are created\n",
            "train and test data are cleaned\n",
            "train and test sequences are extracted\n",
            "100% 266/266 [00:00<00:00, 13249.63it/s]\n",
            "100% 67/67 [00:00<00:00, 13681.52it/s]\n",
            "train and test sequences are folded\n",
            "train and test inputs and targets are created\n",
            "problem skill mapping is created\n",
            "model is created\n",
            "model is compiled\n",
            "start fitting\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 102ms/step - loss: 0.8363 - val_loss: 0.6428\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.6522 - val_loss: 0.5058\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.5367 - val_loss: 0.4228\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.4604 - val_loss: 0.3723\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.4093 - val_loss: 0.3410\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.3746 - val_loss: 0.3206\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.3467 - val_loss: 0.3066\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3308 - val_loss: 0.2964\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.3211 - val_loss: 0.2889\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3083 - val_loss: 0.2832\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3005 - val_loss: 0.2790\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2933 - val_loss: 0.2757\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2881 - val_loss: 0.2730\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2824 - val_loss: 0.2710\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2817 - val_loss: 0.2694\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2797 - val_loss: 0.2677\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2774 - val_loss: 0.2664\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2754 - val_loss: 0.2650\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2755 - val_loss: 0.2640\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2699 - val_loss: 0.2632\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2690 - val_loss: 0.2623\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2671 - val_loss: 0.2616\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2692 - val_loss: 0.2609\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2670 - val_loss: 0.2602\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2664 - val_loss: 0.2596\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2620 - val_loss: 0.2591\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2636 - val_loss: 0.2587\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2624 - val_loss: 0.2584\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2641 - val_loss: 0.2579\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2622 - val_loss: 0.2573\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2621 - val_loss: 0.2566\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2596 - val_loss: 0.2560\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2594 - val_loss: 0.2558\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2591 - val_loss: 0.2557\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2575 - val_loss: 0.2557\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2581 - val_loss: 0.2553\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2580 - val_loss: 0.2549\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2562 - val_loss: 0.2545\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2559 - val_loss: 0.2544\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2572 - val_loss: 0.2549\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2562 - val_loss: 0.2544\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2548 - val_loss: 0.2540\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2556 - val_loss: 0.2536\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2543 - val_loss: 0.2531\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2541 - val_loss: 0.2530\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2555 - val_loss: 0.2528\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2541 - val_loss: 0.2527\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2536 - val_loss: 0.2525\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2536 - val_loss: 0.2523\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2540 - val_loss: 0.2519\n",
            "test auc = 0.9563930341874594 in cv = 1\n",
            "\n",
            " cv 1 finished for stat2011\n",
            "\n",
            "\n",
            " cv 2 starts for stat2011\n",
            "\n",
            "train data in /content/dirve/My Drive/dktt_light/data/stat2011-cv-train-2.csv is loaded\n",
            "test data in /content/dirve/My Drive/dktt_light/data/stat2011-cv-test-2.csv is loaded\n",
            "problem and skill encoders are created\n",
            "train and test data are cleaned\n",
            "train and test sequences are extracted\n",
            "100% 266/266 [00:00<00:00, 10657.95it/s]\n",
            "100% 67/67 [00:00<00:00, 17293.44it/s]\n",
            "train and test sequences are folded\n",
            "train and test inputs and targets are created\n",
            "problem skill mapping is created\n",
            "model is created\n",
            "model is compiled\n",
            "start fitting\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 104ms/step - loss: 0.8454 - val_loss: 0.6545\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6562 - val_loss: 0.5034\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5321 - val_loss: 0.4126\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.4507 - val_loss: 0.3610\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3957 - val_loss: 0.3307\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.3617 - val_loss: 0.3113\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3341 - val_loss: 0.2984\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3181 - val_loss: 0.2895\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3038 - val_loss: 0.2832\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2952 - val_loss: 0.2785\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2896 - val_loss: 0.2748\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2821 - val_loss: 0.2719\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2780 - val_loss: 0.2695\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2762 - val_loss: 0.2674\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2722 - val_loss: 0.2656\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2687 - val_loss: 0.2641\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2671 - val_loss: 0.2627\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2652 - val_loss: 0.2614\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2640 - val_loss: 0.2604\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2626 - val_loss: 0.2593\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2618 - val_loss: 0.2584\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2595 - val_loss: 0.2576\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2567 - val_loss: 0.2569\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2601 - val_loss: 0.2563\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2560 - val_loss: 0.2556\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2555 - val_loss: 0.2550\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2558 - val_loss: 0.2545\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2534 - val_loss: 0.2540\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2532 - val_loss: 0.2537\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2544 - val_loss: 0.2533\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2519 - val_loss: 0.2529\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2522 - val_loss: 0.2526\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2516 - val_loss: 0.2523\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2518 - val_loss: 0.2520\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2494 - val_loss: 0.2517\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2515 - val_loss: 0.2515\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2502 - val_loss: 0.2511\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2480 - val_loss: 0.2510\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2494 - val_loss: 0.2508\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2479 - val_loss: 0.2506\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2482 - val_loss: 0.2503\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2474 - val_loss: 0.2502\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2471 - val_loss: 0.2500\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2469 - val_loss: 0.2497\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2453 - val_loss: 0.2497\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2473 - val_loss: 0.2495\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2456 - val_loss: 0.2493\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2455 - val_loss: 0.2492\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2473 - val_loss: 0.2490\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.2449 - val_loss: 0.2489\n",
            "test auc = 0.946321480983891 in cv = 2\n",
            "\n",
            " cv 2 finished for stat2011\n",
            "\n",
            "\n",
            " cv 3 starts for stat2011\n",
            "\n",
            "train data in /content/dirve/My Drive/dktt_light/data/stat2011-cv-train-3.csv is loaded\n",
            "test data in /content/dirve/My Drive/dktt_light/data/stat2011-cv-test-3.csv is loaded\n",
            "problem and skill encoders are created\n",
            "train and test data are cleaned\n",
            "train and test sequences are extracted\n",
            "100% 267/267 [00:00<00:00, 10323.37it/s]\n",
            "100% 66/66 [00:00<00:00, 17104.80it/s]\n",
            "train and test sequences are folded\n",
            "train and test inputs and targets are created\n",
            "problem skill mapping is created\n",
            "model is created\n",
            "model is compiled\n",
            "start fitting\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 103ms/step - loss: 0.8588 - val_loss: 0.6723\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.6567 - val_loss: 0.5227\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.5268 - val_loss: 0.4269\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.4394 - val_loss: 0.3700\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.3788 - val_loss: 0.3365\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3471 - val_loss: 0.3156\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3226 - val_loss: 0.3023\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3054 - val_loss: 0.2937\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2942 - val_loss: 0.2877\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2878 - val_loss: 0.2834\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2805 - val_loss: 0.2799\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2779 - val_loss: 0.2773\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2749 - val_loss: 0.2750\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2713 - val_loss: 0.2731\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2674 - val_loss: 0.2714\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2680 - val_loss: 0.2699\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2647 - val_loss: 0.2684\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2619 - val_loss: 0.2673\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2620 - val_loss: 0.2661\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2611 - val_loss: 0.2650\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2588 - val_loss: 0.2642\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2587 - val_loss: 0.2632\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2575 - val_loss: 0.2626\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2554 - val_loss: 0.2619\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2542 - val_loss: 0.2614\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2535 - val_loss: 0.2609\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2530 - val_loss: 0.2604\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2519 - val_loss: 0.2600\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2526 - val_loss: 0.2597\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2509 - val_loss: 0.2594\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2518 - val_loss: 0.2590\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2514 - val_loss: 0.2588\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2512 - val_loss: 0.2584\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2506 - val_loss: 0.2582\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2503 - val_loss: 0.2578\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2486 - val_loss: 0.2574\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2497 - val_loss: 0.2574\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2488 - val_loss: 0.2573\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2469 - val_loss: 0.2569\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2468 - val_loss: 0.2567\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2473 - val_loss: 0.2566\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2476 - val_loss: 0.2564\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2463 - val_loss: 0.2563\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2454 - val_loss: 0.2561\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2455 - val_loss: 0.2561\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2466 - val_loss: 0.2559\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2448 - val_loss: 0.2559\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2461 - val_loss: 0.2559\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2445 - val_loss: 0.2558\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2442 - val_loss: 0.2556\n",
            "test auc = 0.9540459148612844 in cv = 3\n",
            "\n",
            " cv 3 finished for stat2011\n",
            "\n",
            "\n",
            " cv 4 starts for stat2011\n",
            "\n",
            "train data in /content/dirve/My Drive/dktt_light/data/stat2011-cv-train-4.csv is loaded\n",
            "test data in /content/dirve/My Drive/dktt_light/data/stat2011-cv-test-4.csv is loaded\n",
            "problem and skill encoders are created\n",
            "train and test data are cleaned\n",
            "train and test sequences are extracted\n",
            "100% 267/267 [00:00<00:00, 10627.76it/s]\n",
            "100% 66/66 [00:00<00:00, 16262.72it/s]\n",
            "train and test sequences are folded\n",
            "train and test inputs and targets are created\n",
            "problem skill mapping is created\n",
            "model is created\n",
            "model is compiled\n",
            "start fitting\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 103ms/step - loss: 0.8499 - val_loss: 0.6582\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6582 - val_loss: 0.5074\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5310 - val_loss: 0.4185\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4499 - val_loss: 0.3660\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3971 - val_loss: 0.3349\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3589 - val_loss: 0.3150\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3341 - val_loss: 0.3022\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3172 - val_loss: 0.2934\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3044 - val_loss: 0.2871\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2943 - val_loss: 0.2826\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2893 - val_loss: 0.2792\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2830 - val_loss: 0.2767\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2802 - val_loss: 0.2746\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2753 - val_loss: 0.2729\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2721 - val_loss: 0.2715\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2712 - val_loss: 0.2703\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2691 - val_loss: 0.2692\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2681 - val_loss: 0.2681\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2663 - val_loss: 0.2670\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2631 - val_loss: 0.2661\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2621 - val_loss: 0.2653\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2615 - val_loss: 0.2644\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2626 - val_loss: 0.2638\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2587 - val_loss: 0.2633\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2566 - val_loss: 0.2626\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2567 - val_loss: 0.2620\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2573 - val_loss: 0.2615\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2580 - val_loss: 0.2611\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2564 - val_loss: 0.2605\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2541 - val_loss: 0.2601\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2559 - val_loss: 0.2598\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2531 - val_loss: 0.2595\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2528 - val_loss: 0.2591\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2506 - val_loss: 0.2589\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2521 - val_loss: 0.2586\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2525 - val_loss: 0.2584\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2514 - val_loss: 0.2581\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2509 - val_loss: 0.2579\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2497 - val_loss: 0.2578\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2507 - val_loss: 0.2576\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2483 - val_loss: 0.2573\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2485 - val_loss: 0.2572\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2482 - val_loss: 0.2569\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2491 - val_loss: 0.2568\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2470 - val_loss: 0.2566\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.2515 - val_loss: 0.2564\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2473 - val_loss: 0.2563\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2465 - val_loss: 0.2562\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2458 - val_loss: 0.2561\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2473 - val_loss: 0.2558\n",
            "test auc = 0.9605475990967804 in cv = 4\n",
            "\n",
            " cv 4 finished for stat2011\n",
            "\n",
            "Model: \"dktt_light\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_shared_weights_4 ( multiple                  6080900   \n",
            "_________________________________________________________________\n",
            "encoder_stack (EncoderStack) multiple                  16674     \n",
            "_________________________________________________________________\n",
            "decoder_stack (DecoderStack) multiple                  0         \n",
            "=================================================================\n",
            "Total params: 6,097,574\n",
            "Trainable params: 95,074\n",
            "Non-trainable params: 6,002,500\n",
            "_________________________________________________________________\n",
            "None\n",
            "average test auc for stat2011 is 0.953855789415836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ybLk04xH-Hp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea74dfb8-4054-4eb5-acbc-eb550ce38262"
      },
      "source": [
        "!python main.py --dataset 'assist2017'"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 03:04:32.666314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "model params are {'params': {'hidden_size': 32, 'confidence': 2, 'temperature': 0.5, 'time_unit': 1, 'layer_postprocess_dropout': 0.1, 'relu_dropout': 0.1, 'attention_dropout': 0.1, 'num_heads': 4, 'shared_weights': False, 'filter_size': 64, 'kernal_size': 8, 'mask_out': 'future', 'num_encoder_blocks': 4, 'num_decoder_blocks': 0, 'q_matrix_trainable': True, 'item_difficulty': False}}\n",
            "fit params are {'batch_size': 128, 'epochs': 200, 'validation_split': 0.1}\n",
            "optimizer params = {'initial_learning_rate': 0.001, 'decay_steps': 100, 'decay_rate': 1.0, 'staircase': True}\n",
            "loss params = {'smoothing': 0.1}\n",
            "\n",
            " cv 0 starts for assist2017\n",
            "\n",
            "train data in /content/dirve/My Drive/dktt_light/data/assist2017-cv-train-0.csv is loaded\n",
            "test data in /content/dirve/My Drive/dktt_light/data/assist2017-cv-test-0.csv is loaded\n",
            "dataset = assist2017\n",
            "num of attempts = 938.705 K\n",
            "num of students = 1709\n",
            "num of skills = 102\n",
            "num of items = 4117\n",
            "problem and skill encoders are created\n",
            "train and test data are cleaned\n",
            "train and test sequences are extracted\n",
            "100% 1367/1367 [00:00<00:00, 5531.98it/s]\n",
            "100% 342/342 [00:00<00:00, 11105.06it/s]\n",
            "train and test sequences are folded\n",
            "train and test inputs and targets are created\n",
            "problem skill mapping is created\n",
            "2021-04-08 03:05:08.890810: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-08 03:05:08.891664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-08 03:05:08.895837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:05:08.896407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-04-08 03:05:08.896443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-08 03:05:08.898356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-08 03:05:08.898434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-04-08 03:05:08.899920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-08 03:05:08.900249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-08 03:05:08.901759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-08 03:05:08.902222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-04-08 03:05:08.902404: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-04-08 03:05:08.902507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:05:08.903103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:05:08.903650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-08 03:05:08.904016: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-08 03:05:08.904128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:05:08.904701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-04-08 03:05:08.904727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-08 03:05:08.904756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-08 03:05:08.904776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-04-08 03:05:08.904796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-08 03:05:08.904816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-08 03:05:08.904836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-08 03:05:08.904855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-04-08 03:05:08.904874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-04-08 03:05:08.904938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:05:08.905501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:05:08.906015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-08 03:05:08.906068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-08 03:05:09.339287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-08 03:05:09.339347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-04-08 03:05:09.339363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-04-08 03:05:09.339611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:05:09.340380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:05:09.341020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-08 03:05:09.341536: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-08 03:05:09.341584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "model is created\n",
            "model is compiled\n",
            "start fitting\n",
            "2021-04-08 03:05:09.411281: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-04-08 03:05:09.411685: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /content/dirve/My Drive/dktt_light/dktt_light/model.py:198: DenseEinsum.__init__ (from official.nlp.modeling.layers.dense_einsum) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "DenseEinsum is deprecated. Please use tf.keras.experimental.EinsumDense layer instead.\n",
            "2021-04-08 03:05:14.104133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-08 03:05:14.344463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "46/46 [==============================] - 9s 86ms/step - loss: 0.7728 - val_loss: 0.6601\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6575 - val_loss: 0.6570\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6549 - val_loss: 0.6543\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6514 - val_loss: 0.6517\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6488 - val_loss: 0.6487\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6446 - val_loss: 0.6444\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6402 - val_loss: 0.6387\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6345 - val_loss: 0.6321\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6274 - val_loss: 0.6257\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6210 - val_loss: 0.6211\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6169 - val_loss: 0.6176\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6127 - val_loss: 0.6148\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6093 - val_loss: 0.6123\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6081 - val_loss: 0.6105\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6058 - val_loss: 0.6096\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6050 - val_loss: 0.6084\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6043 - val_loss: 0.6085\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6028 - val_loss: 0.6071\n",
            "Epoch 19/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6014 - val_loss: 0.6062\n",
            "Epoch 20/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.6007 - val_loss: 0.6058\n",
            "Epoch 21/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5997 - val_loss: 0.6055\n",
            "Epoch 22/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5989 - val_loss: 0.6051\n",
            "Epoch 23/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5989 - val_loss: 0.6045\n",
            "Epoch 24/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5987 - val_loss: 0.6048\n",
            "Epoch 25/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5962 - val_loss: 0.6042\n",
            "Epoch 26/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5970 - val_loss: 0.6040\n",
            "Epoch 27/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5964 - val_loss: 0.6037\n",
            "Epoch 28/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5956 - val_loss: 0.6033\n",
            "Epoch 29/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5944 - val_loss: 0.6032\n",
            "Epoch 30/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5948 - val_loss: 0.6030\n",
            "Epoch 31/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5948 - val_loss: 0.6031\n",
            "Epoch 32/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5949 - val_loss: 0.6026\n",
            "Epoch 33/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5942 - val_loss: 0.6025\n",
            "Epoch 34/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5943 - val_loss: 0.6025\n",
            "Epoch 35/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5936 - val_loss: 0.6025\n",
            "Epoch 36/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5938 - val_loss: 0.6022\n",
            "Epoch 37/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5920 - val_loss: 0.6017\n",
            "Epoch 38/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5921 - val_loss: 0.6012\n",
            "Epoch 39/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5907 - val_loss: 0.6012\n",
            "Epoch 40/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5906 - val_loss: 0.6011\n",
            "Epoch 41/200\n",
            "46/46 [==============================] - 3s 68ms/step - loss: 0.5910 - val_loss: 0.6007\n",
            "Epoch 42/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5910 - val_loss: 0.6008\n",
            "Epoch 43/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5898 - val_loss: 0.6007\n",
            "Epoch 44/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5905 - val_loss: 0.6007\n",
            "Epoch 45/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5898 - val_loss: 0.6003\n",
            "Epoch 46/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5891 - val_loss: 0.5997\n",
            "Epoch 47/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5895 - val_loss: 0.5993\n",
            "Epoch 48/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5894 - val_loss: 0.5992\n",
            "Epoch 49/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5881 - val_loss: 0.5994\n",
            "Epoch 50/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5883 - val_loss: 0.5989\n",
            "Epoch 51/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5874 - val_loss: 0.5987\n",
            "Epoch 52/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5874 - val_loss: 0.5982\n",
            "Epoch 53/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5874 - val_loss: 0.5979\n",
            "Epoch 54/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5870 - val_loss: 0.5976\n",
            "Epoch 55/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5864 - val_loss: 0.5973\n",
            "Epoch 56/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5869 - val_loss: 0.5969\n",
            "Epoch 57/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5860 - val_loss: 0.5972\n",
            "Epoch 58/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5850 - val_loss: 0.5969\n",
            "Epoch 59/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5847 - val_loss: 0.5960\n",
            "Epoch 60/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5843 - val_loss: 0.5961\n",
            "Epoch 61/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5844 - val_loss: 0.5955\n",
            "Epoch 62/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5844 - val_loss: 0.5952\n",
            "Epoch 63/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5833 - val_loss: 0.5953\n",
            "Epoch 64/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5835 - val_loss: 0.5942\n",
            "Epoch 65/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5822 - val_loss: 0.5942\n",
            "Epoch 66/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5824 - val_loss: 0.5936\n",
            "Epoch 67/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5816 - val_loss: 0.5931\n",
            "Epoch 68/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5809 - val_loss: 0.5942\n",
            "Epoch 69/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5819 - val_loss: 0.5928\n",
            "Epoch 70/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5809 - val_loss: 0.5925\n",
            "Epoch 71/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5807 - val_loss: 0.5919\n",
            "Epoch 72/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5802 - val_loss: 0.5920\n",
            "Epoch 73/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5799 - val_loss: 0.5917\n",
            "Epoch 74/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5797 - val_loss: 0.5914\n",
            "Epoch 75/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5797 - val_loss: 0.5913\n",
            "Epoch 76/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5797 - val_loss: 0.5902\n",
            "Epoch 77/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5787 - val_loss: 0.5900\n",
            "Epoch 78/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5785 - val_loss: 0.5900\n",
            "Epoch 79/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5779 - val_loss: 0.5892\n",
            "Epoch 80/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5786 - val_loss: 0.5890\n",
            "Epoch 81/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5778 - val_loss: 0.5889\n",
            "Epoch 82/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5771 - val_loss: 0.5897\n",
            "Epoch 83/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5774 - val_loss: 0.5887\n",
            "Epoch 84/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5762 - val_loss: 0.5883\n",
            "Epoch 85/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5755 - val_loss: 0.5879\n",
            "Epoch 86/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5764 - val_loss: 0.5877\n",
            "Epoch 87/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5752 - val_loss: 0.5879\n",
            "Epoch 88/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5753 - val_loss: 0.5875\n",
            "Epoch 89/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5750 - val_loss: 0.5868\n",
            "Epoch 90/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5752 - val_loss: 0.5872\n",
            "Epoch 91/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5744 - val_loss: 0.5864\n",
            "Epoch 92/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5744 - val_loss: 0.5865\n",
            "Epoch 93/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5739 - val_loss: 0.5859\n",
            "Epoch 94/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5731 - val_loss: 0.5861\n",
            "Epoch 95/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5736 - val_loss: 0.5867\n",
            "Epoch 96/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5727 - val_loss: 0.5853\n",
            "Epoch 97/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5736 - val_loss: 0.5857\n",
            "Epoch 98/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5727 - val_loss: 0.5855\n",
            "Epoch 99/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5717 - val_loss: 0.5854\n",
            "Epoch 100/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5719 - val_loss: 0.5848\n",
            "Epoch 101/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5722 - val_loss: 0.5854\n",
            "Epoch 102/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5719 - val_loss: 0.5849\n",
            "Epoch 103/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5717 - val_loss: 0.5843\n",
            "Epoch 104/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5722 - val_loss: 0.5844\n",
            "Epoch 105/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5716 - val_loss: 0.5852\n",
            "Epoch 106/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5715 - val_loss: 0.5841\n",
            "Epoch 107/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5707 - val_loss: 0.5843\n",
            "Epoch 108/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5706 - val_loss: 0.5841\n",
            "Epoch 109/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5698 - val_loss: 0.5843\n",
            "Epoch 110/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5698 - val_loss: 0.5838\n",
            "Epoch 111/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5704 - val_loss: 0.5836\n",
            "Epoch 112/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5701 - val_loss: 0.5833\n",
            "Epoch 113/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5698 - val_loss: 0.5839\n",
            "Epoch 114/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5692 - val_loss: 0.5832\n",
            "Epoch 115/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5693 - val_loss: 0.5834\n",
            "Epoch 116/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5698 - val_loss: 0.5829\n",
            "Epoch 117/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5688 - val_loss: 0.5839\n",
            "Epoch 118/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5688 - val_loss: 0.5829\n",
            "Epoch 119/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5691 - val_loss: 0.5830\n",
            "Epoch 120/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5679 - val_loss: 0.5827\n",
            "Epoch 121/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5689 - val_loss: 0.5830\n",
            "Epoch 122/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5677 - val_loss: 0.5827\n",
            "Epoch 123/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5687 - val_loss: 0.5818\n",
            "Epoch 124/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5675 - val_loss: 0.5822\n",
            "Epoch 125/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5674 - val_loss: 0.5823\n",
            "Epoch 126/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5678 - val_loss: 0.5823\n",
            "Epoch 127/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5668 - val_loss: 0.5820\n",
            "Epoch 128/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5668 - val_loss: 0.5825\n",
            "Epoch 129/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5670 - val_loss: 0.5818\n",
            "Epoch 130/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5670 - val_loss: 0.5816\n",
            "Epoch 131/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5670 - val_loss: 0.5814\n",
            "Epoch 132/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5672 - val_loss: 0.5815\n",
            "Epoch 133/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5676 - val_loss: 0.5820\n",
            "Epoch 134/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5670 - val_loss: 0.5820\n",
            "Epoch 135/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5660 - val_loss: 0.5818\n",
            "Epoch 136/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5659 - val_loss: 0.5814\n",
            "Epoch 137/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5664 - val_loss: 0.5818\n",
            "Epoch 138/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5658 - val_loss: 0.5812\n",
            "Epoch 139/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5658 - val_loss: 0.5821\n",
            "Epoch 140/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5651 - val_loss: 0.5825\n",
            "Epoch 141/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5660 - val_loss: 0.5808\n",
            "Epoch 142/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5644 - val_loss: 0.5807\n",
            "Epoch 143/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5658 - val_loss: 0.5807\n",
            "Epoch 144/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5656 - val_loss: 0.5800\n",
            "Epoch 145/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5648 - val_loss: 0.5811\n",
            "Epoch 146/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5655 - val_loss: 0.5795\n",
            "Epoch 147/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5652 - val_loss: 0.5800\n",
            "Epoch 148/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5648 - val_loss: 0.5793\n",
            "Epoch 149/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5643 - val_loss: 0.5789\n",
            "Epoch 150/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5632 - val_loss: 0.5779\n",
            "Epoch 151/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5638 - val_loss: 0.5785\n",
            "Epoch 152/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5634 - val_loss: 0.5776\n",
            "Epoch 153/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5630 - val_loss: 0.5785\n",
            "Epoch 154/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5625 - val_loss: 0.5772\n",
            "Epoch 155/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5636 - val_loss: 0.5773\n",
            "Epoch 156/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5621 - val_loss: 0.5776\n",
            "Epoch 157/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5606 - val_loss: 0.5770\n",
            "Epoch 158/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5605 - val_loss: 0.5773\n",
            "Epoch 159/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5619 - val_loss: 0.5775\n",
            "Epoch 160/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5625 - val_loss: 0.5770\n",
            "Epoch 161/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5629 - val_loss: 0.5776\n",
            "Epoch 162/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5624 - val_loss: 0.5770\n",
            "Epoch 163/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5622 - val_loss: 0.5770\n",
            "Epoch 164/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5617 - val_loss: 0.5774\n",
            "Epoch 165/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5610 - val_loss: 0.5766\n",
            "Epoch 166/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5617 - val_loss: 0.5771\n",
            "Epoch 167/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5617 - val_loss: 0.5764\n",
            "Epoch 168/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5597 - val_loss: 0.5764\n",
            "Epoch 169/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5611 - val_loss: 0.5768\n",
            "Epoch 170/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5604 - val_loss: 0.5760\n",
            "Epoch 171/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5593 - val_loss: 0.5766\n",
            "Epoch 172/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5598 - val_loss: 0.5768\n",
            "Epoch 173/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5609 - val_loss: 0.5763\n",
            "Epoch 174/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5593 - val_loss: 0.5766\n",
            "Epoch 175/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5603 - val_loss: 0.5762\n",
            "Epoch 176/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5599 - val_loss: 0.5770\n",
            "Epoch 177/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5605 - val_loss: 0.5765\n",
            "Epoch 178/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5585 - val_loss: 0.5763\n",
            "Epoch 179/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5599 - val_loss: 0.5764\n",
            "Epoch 180/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5595 - val_loss: 0.5761\n",
            "Epoch 181/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5597 - val_loss: 0.5761\n",
            "Epoch 182/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5597 - val_loss: 0.5760\n",
            "Epoch 183/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5594 - val_loss: 0.5765\n",
            "Epoch 184/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5595 - val_loss: 0.5764\n",
            "Epoch 185/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5594 - val_loss: 0.5769\n",
            "Epoch 186/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5583 - val_loss: 0.5759\n",
            "Epoch 187/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5590 - val_loss: 0.5761\n",
            "Epoch 188/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5591 - val_loss: 0.5761\n",
            "Epoch 189/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5578 - val_loss: 0.5757\n",
            "Epoch 190/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5576 - val_loss: 0.5758\n",
            "Epoch 191/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5591 - val_loss: 0.5759\n",
            "Epoch 192/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5579 - val_loss: 0.5757\n",
            "Epoch 193/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5578 - val_loss: 0.5761\n",
            "Epoch 194/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5569 - val_loss: 0.5760\n",
            "Epoch 195/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5584 - val_loss: 0.5758\n",
            "Epoch 196/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5569 - val_loss: 0.5757\n",
            "Epoch 197/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5569 - val_loss: 0.5756\n",
            "Epoch 198/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5574 - val_loss: 0.5756\n",
            "Epoch 199/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5570 - val_loss: 0.5765\n",
            "Epoch 200/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5589 - val_loss: 0.5756\n",
            "test auc = 0.778586364932603 in cv = 0\n",
            "\n",
            " cv 0 finished for assist2017\n",
            "\n",
            "\n",
            " cv 1 starts for assist2017\n",
            "\n",
            "train data in /content/dirve/My Drive/dktt_light/data/assist2017-cv-train-1.csv is loaded\n",
            "test data in /content/dirve/My Drive/dktt_light/data/assist2017-cv-test-1.csv is loaded\n",
            "problem and skill encoders are created\n",
            "train and test data are cleaned\n",
            "train and test sequences are extracted\n",
            "100% 1367/1367 [00:00<00:00, 10597.69it/s]\n",
            "100% 342/342 [00:00<00:00, 10858.92it/s]\n",
            "train and test sequences are folded\n",
            "train and test inputs and targets are created\n",
            "problem skill mapping is created\n",
            "model is created\n",
            "model is compiled\n",
            "start fitting\n",
            "Epoch 1/200\n",
            "46/46 [==============================] - 7s 83ms/step - loss: 0.7861 - val_loss: 0.6591\n",
            "Epoch 2/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6561 - val_loss: 0.6548\n",
            "Epoch 3/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6532 - val_loss: 0.6524\n",
            "Epoch 4/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6488 - val_loss: 0.6495\n",
            "Epoch 5/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6468 - val_loss: 0.6459\n",
            "Epoch 6/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6429 - val_loss: 0.6412\n",
            "Epoch 7/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6368 - val_loss: 0.6352\n",
            "Epoch 8/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6308 - val_loss: 0.6283\n",
            "Epoch 9/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6252 - val_loss: 0.6223\n",
            "Epoch 10/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6179 - val_loss: 0.6179\n",
            "Epoch 11/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6154 - val_loss: 0.6149\n",
            "Epoch 12/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6117 - val_loss: 0.6123\n",
            "Epoch 13/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6084 - val_loss: 0.6105\n",
            "Epoch 14/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6061 - val_loss: 0.6088\n",
            "Epoch 15/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6038 - val_loss: 0.6079\n",
            "Epoch 16/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6035 - val_loss: 0.6071\n",
            "Epoch 17/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6017 - val_loss: 0.6065\n",
            "Epoch 18/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6016 - val_loss: 0.6059\n",
            "Epoch 19/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.6006 - val_loss: 0.6054\n",
            "Epoch 20/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5996 - val_loss: 0.6047\n",
            "Epoch 21/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5992 - val_loss: 0.6047\n",
            "Epoch 22/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5986 - val_loss: 0.6045\n",
            "Epoch 23/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5982 - val_loss: 0.6043\n",
            "Epoch 24/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5978 - val_loss: 0.6028\n",
            "Epoch 25/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5971 - val_loss: 0.6028\n",
            "Epoch 26/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5963 - val_loss: 0.6021\n",
            "Epoch 27/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5966 - val_loss: 0.6023\n",
            "Epoch 28/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5956 - val_loss: 0.6019\n",
            "Epoch 29/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5952 - val_loss: 0.6012\n",
            "Epoch 30/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5943 - val_loss: 0.6016\n",
            "Epoch 31/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5946 - val_loss: 0.6006\n",
            "Epoch 32/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5934 - val_loss: 0.6004\n",
            "Epoch 33/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5929 - val_loss: 0.6007\n",
            "Epoch 34/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5930 - val_loss: 0.6002\n",
            "Epoch 35/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5935 - val_loss: 0.6002\n",
            "Epoch 36/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5920 - val_loss: 0.5997\n",
            "Epoch 37/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5922 - val_loss: 0.5992\n",
            "Epoch 38/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5916 - val_loss: 0.5988\n",
            "Epoch 39/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5909 - val_loss: 0.5985\n",
            "Epoch 40/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5902 - val_loss: 0.5983\n",
            "Epoch 41/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5919 - val_loss: 0.5981\n",
            "Epoch 42/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5899 - val_loss: 0.5981\n",
            "Epoch 43/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5898 - val_loss: 0.5971\n",
            "Epoch 44/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5887 - val_loss: 0.5975\n",
            "Epoch 45/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5892 - val_loss: 0.5979\n",
            "Epoch 46/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5891 - val_loss: 0.5963\n",
            "Epoch 47/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5879 - val_loss: 0.5966\n",
            "Epoch 48/200\n",
            "46/46 [==============================] - 3s 71ms/step - loss: 0.5883 - val_loss: 0.5961\n",
            "Epoch 49/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5872 - val_loss: 0.5959\n",
            "Epoch 50/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5870 - val_loss: 0.5960\n",
            "Epoch 51/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5875 - val_loss: 0.5953\n",
            "Epoch 52/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5875 - val_loss: 0.5948\n",
            "Epoch 53/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5866 - val_loss: 0.5946\n",
            "Epoch 54/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5862 - val_loss: 0.5939\n",
            "Epoch 55/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5850 - val_loss: 0.5939\n",
            "Epoch 56/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5848 - val_loss: 0.5938\n",
            "Epoch 57/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5853 - val_loss: 0.5933\n",
            "Epoch 58/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5845 - val_loss: 0.5925\n",
            "Epoch 59/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5840 - val_loss: 0.5925\n",
            "Epoch 60/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5839 - val_loss: 0.5924\n",
            "Epoch 61/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5840 - val_loss: 0.5919\n",
            "Epoch 62/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5830 - val_loss: 0.5913\n",
            "Epoch 63/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5825 - val_loss: 0.5911\n",
            "Epoch 64/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5827 - val_loss: 0.5908\n",
            "Epoch 65/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5816 - val_loss: 0.5904\n",
            "Epoch 66/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5811 - val_loss: 0.5898\n",
            "Epoch 67/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5810 - val_loss: 0.5893\n",
            "Epoch 68/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5809 - val_loss: 0.5890\n",
            "Epoch 69/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5816 - val_loss: 0.5890\n",
            "Epoch 70/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5802 - val_loss: 0.5882\n",
            "Epoch 71/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5791 - val_loss: 0.5880\n",
            "Epoch 72/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5810 - val_loss: 0.5893\n",
            "Epoch 73/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5790 - val_loss: 0.5877\n",
            "Epoch 74/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5796 - val_loss: 0.5874\n",
            "Epoch 75/200\n",
            "46/46 [==============================] - 3s 71ms/step - loss: 0.5779 - val_loss: 0.5869\n",
            "Epoch 76/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5774 - val_loss: 0.5866\n",
            "Epoch 77/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5780 - val_loss: 0.5867\n",
            "Epoch 78/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5775 - val_loss: 0.5860\n",
            "Epoch 79/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5784 - val_loss: 0.5858\n",
            "Epoch 80/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5770 - val_loss: 0.5853\n",
            "Epoch 81/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5762 - val_loss: 0.5855\n",
            "Epoch 82/200\n",
            "46/46 [==============================] - 3s 71ms/step - loss: 0.5760 - val_loss: 0.5855\n",
            "Epoch 83/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5767 - val_loss: 0.5845\n",
            "Epoch 84/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5767 - val_loss: 0.5849\n",
            "Epoch 85/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5765 - val_loss: 0.5840\n",
            "Epoch 86/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5755 - val_loss: 0.5839\n",
            "Epoch 87/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5755 - val_loss: 0.5845\n",
            "Epoch 88/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5755 - val_loss: 0.5836\n",
            "Epoch 89/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5734 - val_loss: 0.5832\n",
            "Epoch 90/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5743 - val_loss: 0.5829\n",
            "Epoch 91/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5747 - val_loss: 0.5835\n",
            "Epoch 92/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5735 - val_loss: 0.5829\n",
            "Epoch 93/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5732 - val_loss: 0.5830\n",
            "Epoch 94/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5734 - val_loss: 0.5830\n",
            "Epoch 95/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5738 - val_loss: 0.5817\n",
            "Epoch 96/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5724 - val_loss: 0.5819\n",
            "Epoch 97/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5720 - val_loss: 0.5821\n",
            "Epoch 98/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5743 - val_loss: 0.5812\n",
            "Epoch 99/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5715 - val_loss: 0.5814\n",
            "Epoch 100/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5712 - val_loss: 0.5809\n",
            "Epoch 101/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5715 - val_loss: 0.5815\n",
            "Epoch 102/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5718 - val_loss: 0.5817\n",
            "Epoch 103/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5709 - val_loss: 0.5813\n",
            "Epoch 104/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5711 - val_loss: 0.5806\n",
            "Epoch 105/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5717 - val_loss: 0.5808\n",
            "Epoch 106/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5721 - val_loss: 0.5806\n",
            "Epoch 107/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5706 - val_loss: 0.5799\n",
            "Epoch 108/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5709 - val_loss: 0.5805\n",
            "Epoch 109/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5715 - val_loss: 0.5803\n",
            "Epoch 110/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5707 - val_loss: 0.5797\n",
            "Epoch 111/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5699 - val_loss: 0.5795\n",
            "Epoch 112/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5693 - val_loss: 0.5793\n",
            "Epoch 113/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5682 - val_loss: 0.5788\n",
            "Epoch 114/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5697 - val_loss: 0.5792\n",
            "Epoch 115/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5685 - val_loss: 0.5788\n",
            "Epoch 116/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5697 - val_loss: 0.5789\n",
            "Epoch 117/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5693 - val_loss: 0.5788\n",
            "Epoch 118/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5698 - val_loss: 0.5796\n",
            "Epoch 119/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5692 - val_loss: 0.5783\n",
            "Epoch 120/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5679 - val_loss: 0.5782\n",
            "Epoch 121/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5677 - val_loss: 0.5776\n",
            "Epoch 122/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5678 - val_loss: 0.5781\n",
            "Epoch 123/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5671 - val_loss: 0.5773\n",
            "Epoch 124/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5680 - val_loss: 0.5785\n",
            "Epoch 125/200\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.5676 - val_loss: 0.5781\n",
            "Epoch 126/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5679 - val_loss: 0.5780\n",
            "Epoch 127/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5692 - val_loss: 0.5769\n",
            "Epoch 128/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5690 - val_loss: 0.5771\n",
            "Epoch 129/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5689 - val_loss: 0.5774\n",
            "Epoch 130/200\n",
            "46/46 [==============================] - 3s 71ms/step - loss: 0.5682 - val_loss: 0.5767\n",
            "Epoch 131/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5670 - val_loss: 0.5764\n",
            "Epoch 132/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5678 - val_loss: 0.5751\n",
            "Epoch 133/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5663 - val_loss: 0.5756\n",
            "Epoch 134/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5659 - val_loss: 0.5748\n",
            "Epoch 135/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5671 - val_loss: 0.5746\n",
            "Epoch 136/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5655 - val_loss: 0.5753\n",
            "Epoch 137/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5655 - val_loss: 0.5746\n",
            "Epoch 138/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5659 - val_loss: 0.5748\n",
            "Epoch 139/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5654 - val_loss: 0.5736\n",
            "Epoch 140/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5652 - val_loss: 0.5737\n",
            "Epoch 141/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5658 - val_loss: 0.5734\n",
            "Epoch 142/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5660 - val_loss: 0.5730\n",
            "Epoch 143/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5648 - val_loss: 0.5735\n",
            "Epoch 144/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5653 - val_loss: 0.5734\n",
            "Epoch 145/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5644 - val_loss: 0.5729\n",
            "Epoch 146/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5639 - val_loss: 0.5729\n",
            "Epoch 147/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5637 - val_loss: 0.5734\n",
            "Epoch 148/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5632 - val_loss: 0.5731\n",
            "Epoch 149/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5637 - val_loss: 0.5738\n",
            "Epoch 150/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5642 - val_loss: 0.5731\n",
            "Epoch 151/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5628 - val_loss: 0.5726\n",
            "Epoch 152/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5636 - val_loss: 0.5726\n",
            "Epoch 153/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5642 - val_loss: 0.5722\n",
            "Epoch 154/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5628 - val_loss: 0.5725\n",
            "Epoch 155/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5633 - val_loss: 0.5724\n",
            "Epoch 156/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5619 - val_loss: 0.5721\n",
            "Epoch 157/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5623 - val_loss: 0.5719\n",
            "Epoch 158/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5632 - val_loss: 0.5732\n",
            "Epoch 159/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5618 - val_loss: 0.5722\n",
            "Epoch 160/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5621 - val_loss: 0.5721\n",
            "Epoch 161/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5610 - val_loss: 0.5719\n",
            "Epoch 162/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5625 - val_loss: 0.5723\n",
            "Epoch 163/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5628 - val_loss: 0.5722\n",
            "Epoch 164/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5622 - val_loss: 0.5712\n",
            "Epoch 165/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5610 - val_loss: 0.5716\n",
            "Epoch 166/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5618 - val_loss: 0.5722\n",
            "Epoch 167/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5617 - val_loss: 0.5712\n",
            "Epoch 168/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5612 - val_loss: 0.5720\n",
            "Epoch 169/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5605 - val_loss: 0.5718\n",
            "Epoch 170/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5607 - val_loss: 0.5715\n",
            "Epoch 171/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5598 - val_loss: 0.5714\n",
            "Epoch 172/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5618 - val_loss: 0.5712\n",
            "Epoch 173/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5604 - val_loss: 0.5713\n",
            "Epoch 174/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5604 - val_loss: 0.5715\n",
            "Epoch 175/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5619 - val_loss: 0.5715\n",
            "Epoch 176/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5603 - val_loss: 0.5716\n",
            "Epoch 177/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5611 - val_loss: 0.5707\n",
            "Epoch 178/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5599 - val_loss: 0.5708\n",
            "Epoch 179/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5605 - val_loss: 0.5711\n",
            "Epoch 180/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5611 - val_loss: 0.5708\n",
            "Epoch 181/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5584 - val_loss: 0.5703\n",
            "Epoch 182/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5604 - val_loss: 0.5711\n",
            "Epoch 183/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5592 - val_loss: 0.5709\n",
            "Epoch 184/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5594 - val_loss: 0.5707\n",
            "Epoch 185/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5597 - val_loss: 0.5706\n",
            "Epoch 186/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5583 - val_loss: 0.5704\n",
            "Epoch 187/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5593 - val_loss: 0.5708\n",
            "Epoch 188/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5584 - val_loss: 0.5706\n",
            "Epoch 189/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5588 - val_loss: 0.5700\n",
            "Epoch 190/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5594 - val_loss: 0.5706\n",
            "Epoch 191/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5589 - val_loss: 0.5702\n",
            "Epoch 192/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5578 - val_loss: 0.5707\n",
            "Epoch 193/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5590 - val_loss: 0.5705\n",
            "Epoch 194/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5590 - val_loss: 0.5705\n",
            "Epoch 195/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5580 - val_loss: 0.5704\n",
            "Epoch 196/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5573 - val_loss: 0.5699\n",
            "Epoch 197/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5587 - val_loss: 0.5700\n",
            "Epoch 198/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5594 - val_loss: 0.5705\n",
            "Epoch 199/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5576 - val_loss: 0.5708\n",
            "Epoch 200/200\n",
            "46/46 [==============================] - 3s 70ms/step - loss: 0.5584 - val_loss: 0.5700\n",
            "test auc = 0.7845466601898435 in cv = 1\n",
            "\n",
            " cv 1 finished for assist2017\n",
            "\n",
            "\n",
            " cv 2 starts for assist2017\n",
            "\n",
            "train data in /content/dirve/My Drive/dktt_light/data/assist2017-cv-train-2.csv is loaded\n",
            "test data in /content/dirve/My Drive/dktt_light/data/assist2017-cv-test-2.csv is loaded\n",
            "problem and skill encoders are created\n",
            "train and test data are cleaned\n",
            "train and test sequences are extracted\n",
            "100% 1367/1367 [00:00<00:00, 5197.84it/s]\n",
            "100% 342/342 [00:00<00:00, 11273.68it/s]\n",
            "train and test sequences are folded\n",
            "train and test inputs and targets are created\n",
            "problem skill mapping is created\n",
            "model is created\n",
            "model is compiled\n",
            "start fitting\n",
            "Epoch 1/200\n",
            "47/47 [==============================] - 7s 82ms/step - loss: 0.7428 - val_loss: 0.6527\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6555 - val_loss: 0.6499\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6518 - val_loss: 0.6466\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6476 - val_loss: 0.6426\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6414 - val_loss: 0.6345\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6325 - val_loss: 0.6281\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6279 - val_loss: 0.6224\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6211 - val_loss: 0.6176\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6158 - val_loss: 0.6138\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6122 - val_loss: 0.6106\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6098 - val_loss: 0.6085\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6067 - val_loss: 0.6071\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6046 - val_loss: 0.6060\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6037 - val_loss: 0.6058\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6033 - val_loss: 0.6046\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6019 - val_loss: 0.6042\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6011 - val_loss: 0.6035\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5992 - val_loss: 0.6029\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5983 - val_loss: 0.6026\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5977 - val_loss: 0.6021\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5990 - val_loss: 0.6022\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5977 - val_loss: 0.6016\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5968 - val_loss: 0.6016\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5978 - val_loss: 0.6009\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5959 - val_loss: 0.6009\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5955 - val_loss: 0.6006\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5956 - val_loss: 0.6002\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5955 - val_loss: 0.6008\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5947 - val_loss: 0.6000\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5947 - val_loss: 0.5997\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5943 - val_loss: 0.5999\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5937 - val_loss: 0.5995\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5925 - val_loss: 0.5994\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5922 - val_loss: 0.5987\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5930 - val_loss: 0.5988\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5924 - val_loss: 0.5982\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5913 - val_loss: 0.5981\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5910 - val_loss: 0.5981\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5913 - val_loss: 0.5975\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5905 - val_loss: 0.5976\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5904 - val_loss: 0.5973\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5901 - val_loss: 0.5970\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5901 - val_loss: 0.5969\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5898 - val_loss: 0.5966\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5884 - val_loss: 0.5963\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5890 - val_loss: 0.5960\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5888 - val_loss: 0.5970\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5880 - val_loss: 0.5962\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5884 - val_loss: 0.5951\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5867 - val_loss: 0.5951\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5879 - val_loss: 0.5950\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5868 - val_loss: 0.5945\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5856 - val_loss: 0.5943\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5861 - val_loss: 0.5942\n",
            "Epoch 55/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5863 - val_loss: 0.5936\n",
            "Epoch 56/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5858 - val_loss: 0.5934\n",
            "Epoch 57/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5853 - val_loss: 0.5928\n",
            "Epoch 58/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5856 - val_loss: 0.5926\n",
            "Epoch 59/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5851 - val_loss: 0.5925\n",
            "Epoch 60/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5841 - val_loss: 0.5923\n",
            "Epoch 61/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5841 - val_loss: 0.5917\n",
            "Epoch 62/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5839 - val_loss: 0.5916\n",
            "Epoch 63/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5827 - val_loss: 0.5911\n",
            "Epoch 64/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5832 - val_loss: 0.5916\n",
            "Epoch 65/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5827 - val_loss: 0.5906\n",
            "Epoch 66/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5821 - val_loss: 0.5907\n",
            "Epoch 67/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5817 - val_loss: 0.5902\n",
            "Epoch 68/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5828 - val_loss: 0.5896\n",
            "Epoch 69/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5812 - val_loss: 0.5893\n",
            "Epoch 70/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5817 - val_loss: 0.5891\n",
            "Epoch 71/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5808 - val_loss: 0.5892\n",
            "Epoch 72/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5813 - val_loss: 0.5887\n",
            "Epoch 73/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5807 - val_loss: 0.5881\n",
            "Epoch 74/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5794 - val_loss: 0.5880\n",
            "Epoch 75/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5809 - val_loss: 0.5877\n",
            "Epoch 76/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5792 - val_loss: 0.5874\n",
            "Epoch 77/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5786 - val_loss: 0.5871\n",
            "Epoch 78/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5803 - val_loss: 0.5874\n",
            "Epoch 79/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5790 - val_loss: 0.5870\n",
            "Epoch 80/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5783 - val_loss: 0.5871\n",
            "Epoch 81/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5778 - val_loss: 0.5858\n",
            "Epoch 82/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5786 - val_loss: 0.5860\n",
            "Epoch 83/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5784 - val_loss: 0.5861\n",
            "Epoch 84/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5775 - val_loss: 0.5860\n",
            "Epoch 85/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5773 - val_loss: 0.5857\n",
            "Epoch 86/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5772 - val_loss: 0.5851\n",
            "Epoch 87/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5773 - val_loss: 0.5851\n",
            "Epoch 88/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5760 - val_loss: 0.5854\n",
            "Epoch 89/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5763 - val_loss: 0.5849\n",
            "Epoch 90/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5765 - val_loss: 0.5843\n",
            "Epoch 91/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5761 - val_loss: 0.5847\n",
            "Epoch 92/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5762 - val_loss: 0.5852\n",
            "Epoch 93/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5760 - val_loss: 0.5842\n",
            "Epoch 94/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5754 - val_loss: 0.5839\n",
            "Epoch 95/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5759 - val_loss: 0.5842\n",
            "Epoch 96/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5759 - val_loss: 0.5839\n",
            "Epoch 97/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5751 - val_loss: 0.5836\n",
            "Epoch 98/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5761 - val_loss: 0.5841\n",
            "Epoch 99/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5743 - val_loss: 0.5842\n",
            "Epoch 100/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5742 - val_loss: 0.5832\n",
            "Epoch 101/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5748 - val_loss: 0.5825\n",
            "Epoch 102/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5748 - val_loss: 0.5829\n",
            "Epoch 103/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5739 - val_loss: 0.5825\n",
            "Epoch 104/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5743 - val_loss: 0.5823\n",
            "Epoch 105/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5740 - val_loss: 0.5818\n",
            "Epoch 106/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5725 - val_loss: 0.5807\n",
            "Epoch 107/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5733 - val_loss: 0.5799\n",
            "Epoch 108/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5727 - val_loss: 0.5800\n",
            "Epoch 109/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5739 - val_loss: 0.5796\n",
            "Epoch 110/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5731 - val_loss: 0.5788\n",
            "Epoch 111/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5720 - val_loss: 0.5791\n",
            "Epoch 112/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5716 - val_loss: 0.5790\n",
            "Epoch 113/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5714 - val_loss: 0.5786\n",
            "Epoch 114/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5722 - val_loss: 0.5785\n",
            "Epoch 115/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5723 - val_loss: 0.5783\n",
            "Epoch 116/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5716 - val_loss: 0.5785\n",
            "Epoch 117/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5709 - val_loss: 0.5783\n",
            "Epoch 118/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5707 - val_loss: 0.5778\n",
            "Epoch 119/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5698 - val_loss: 0.5776\n",
            "Epoch 120/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5710 - val_loss: 0.5777\n",
            "Epoch 121/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5706 - val_loss: 0.5777\n",
            "Epoch 122/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5698 - val_loss: 0.5775\n",
            "Epoch 123/200\n",
            "47/47 [==============================] - 3s 71ms/step - loss: 0.5696 - val_loss: 0.5777\n",
            "Epoch 124/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5685 - val_loss: 0.5774\n",
            "Epoch 125/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5680 - val_loss: 0.5771\n",
            "Epoch 126/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5688 - val_loss: 0.5768\n",
            "Epoch 127/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5687 - val_loss: 0.5773\n",
            "Epoch 128/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5682 - val_loss: 0.5767\n",
            "Epoch 129/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5680 - val_loss: 0.5767\n",
            "Epoch 130/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5690 - val_loss: 0.5763\n",
            "Epoch 131/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5691 - val_loss: 0.5764\n",
            "Epoch 132/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5675 - val_loss: 0.5764\n",
            "Epoch 133/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5670 - val_loss: 0.5763\n",
            "Epoch 134/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5678 - val_loss: 0.5761\n",
            "Epoch 135/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5682 - val_loss: 0.5761\n",
            "Epoch 136/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5674 - val_loss: 0.5759\n",
            "Epoch 137/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5679 - val_loss: 0.5762\n",
            "Epoch 138/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5678 - val_loss: 0.5755\n",
            "Epoch 139/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5673 - val_loss: 0.5760\n",
            "Epoch 140/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5674 - val_loss: 0.5753\n",
            "Epoch 141/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5670 - val_loss: 0.5753\n",
            "Epoch 142/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5670 - val_loss: 0.5752\n",
            "Epoch 143/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5662 - val_loss: 0.5751\n",
            "Epoch 144/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5674 - val_loss: 0.5758\n",
            "Epoch 145/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5660 - val_loss: 0.5758\n",
            "Epoch 146/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5660 - val_loss: 0.5758\n",
            "Epoch 147/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5662 - val_loss: 0.5754\n",
            "Epoch 148/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5650 - val_loss: 0.5750\n",
            "Epoch 149/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5656 - val_loss: 0.5758\n",
            "Epoch 150/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5657 - val_loss: 0.5752\n",
            "Epoch 151/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5655 - val_loss: 0.5747\n",
            "Epoch 152/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5650 - val_loss: 0.5750\n",
            "Epoch 153/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5659 - val_loss: 0.5747\n",
            "Epoch 154/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5666 - val_loss: 0.5748\n",
            "Epoch 155/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5651 - val_loss: 0.5746\n",
            "Epoch 156/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5639 - val_loss: 0.5755\n",
            "Epoch 157/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5645 - val_loss: 0.5744\n",
            "Epoch 158/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5667 - val_loss: 0.5746\n",
            "Epoch 159/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5642 - val_loss: 0.5748\n",
            "Epoch 160/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5642 - val_loss: 0.5747\n",
            "Epoch 161/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5649 - val_loss: 0.5743\n",
            "Epoch 162/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5642 - val_loss: 0.5740\n",
            "Epoch 163/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5640 - val_loss: 0.5743\n",
            "Epoch 164/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5631 - val_loss: 0.5737\n",
            "Epoch 165/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5637 - val_loss: 0.5742\n",
            "Epoch 166/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5631 - val_loss: 0.5741\n",
            "Epoch 167/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5635 - val_loss: 0.5738\n",
            "Epoch 168/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5627 - val_loss: 0.5740\n",
            "Epoch 169/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5640 - val_loss: 0.5741\n",
            "Epoch 170/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5644 - val_loss: 0.5740\n",
            "Epoch 171/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5633 - val_loss: 0.5738\n",
            "Epoch 172/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5630 - val_loss: 0.5739\n",
            "Epoch 173/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5636 - val_loss: 0.5738\n",
            "Epoch 174/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5627 - val_loss: 0.5739\n",
            "Epoch 175/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5624 - val_loss: 0.5737\n",
            "Epoch 176/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5633 - val_loss: 0.5741\n",
            "Epoch 177/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5626 - val_loss: 0.5738\n",
            "Epoch 178/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5627 - val_loss: 0.5733\n",
            "Epoch 179/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5643 - val_loss: 0.5733\n",
            "Epoch 180/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5618 - val_loss: 0.5737\n",
            "Epoch 181/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5618 - val_loss: 0.5735\n",
            "Epoch 182/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5632 - val_loss: 0.5730\n",
            "Epoch 183/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5615 - val_loss: 0.5734\n",
            "Epoch 184/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5624 - val_loss: 0.5734\n",
            "Epoch 185/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5617 - val_loss: 0.5731\n",
            "Epoch 186/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5623 - val_loss: 0.5731\n",
            "Epoch 187/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5635 - val_loss: 0.5741\n",
            "Epoch 188/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5646 - val_loss: 0.5735\n",
            "Epoch 189/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5624 - val_loss: 0.5738\n",
            "Epoch 190/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5633 - val_loss: 0.5736\n",
            "Epoch 191/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5618 - val_loss: 0.5726\n",
            "Epoch 192/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5617 - val_loss: 0.5730\n",
            "Epoch 193/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5615 - val_loss: 0.5730\n",
            "Epoch 194/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5609 - val_loss: 0.5728\n",
            "Epoch 195/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5610 - val_loss: 0.5728\n",
            "Epoch 196/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5625 - val_loss: 0.5732\n",
            "Epoch 197/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5613 - val_loss: 0.5734\n",
            "Epoch 198/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5619 - val_loss: 0.5736\n",
            "Epoch 199/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5613 - val_loss: 0.5730\n",
            "Epoch 200/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5635 - val_loss: 0.5741\n",
            "test auc = 0.7783541568996949 in cv = 2\n",
            "\n",
            " cv 2 finished for assist2017\n",
            "\n",
            "\n",
            " cv 3 starts for assist2017\n",
            "\n",
            "train data in /content/dirve/My Drive/dktt_light/data/assist2017-cv-train-3.csv is loaded\n",
            "test data in /content/dirve/My Drive/dktt_light/data/assist2017-cv-test-3.csv is loaded\n",
            "problem and skill encoders are created\n",
            "train and test data are cleaned\n",
            "train and test sequences are extracted\n",
            "100% 1367/1367 [00:00<00:00, 3636.15it/s]\n",
            "100% 342/342 [00:00<00:00, 11991.94it/s]\n",
            "train and test sequences are folded\n",
            "train and test inputs and targets are created\n",
            "problem skill mapping is created\n",
            "model is created\n",
            "model is compiled\n",
            "start fitting\n",
            "Epoch 1/200\n",
            "47/47 [==============================] - 7s 83ms/step - loss: 0.7451 - val_loss: 0.6572\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6554 - val_loss: 0.6533\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6514 - val_loss: 0.6503\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6482 - val_loss: 0.6460\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6433 - val_loss: 0.6389\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6356 - val_loss: 0.6305\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6285 - val_loss: 0.6244\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6222 - val_loss: 0.6188\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6161 - val_loss: 0.6148\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6123 - val_loss: 0.6122\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6091 - val_loss: 0.6098\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6070 - val_loss: 0.6086\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6047 - val_loss: 0.6078\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6041 - val_loss: 0.6063\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6022 - val_loss: 0.6055\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6006 - val_loss: 0.6053\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5998 - val_loss: 0.6046\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5997 - val_loss: 0.6041\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5992 - val_loss: 0.6034\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5983 - val_loss: 0.6027\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5975 - val_loss: 0.6025\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5970 - val_loss: 0.6022\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5973 - val_loss: 0.6019\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5960 - val_loss: 0.6020\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5960 - val_loss: 0.6014\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5954 - val_loss: 0.6011\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5952 - val_loss: 0.6005\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5946 - val_loss: 0.6006\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5941 - val_loss: 0.6002\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5929 - val_loss: 0.5996\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5932 - val_loss: 0.5997\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5929 - val_loss: 0.5993\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5938 - val_loss: 0.5991\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5921 - val_loss: 0.5990\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5925 - val_loss: 0.5984\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5923 - val_loss: 0.5981\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5919 - val_loss: 0.5987\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5918 - val_loss: 0.5977\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5908 - val_loss: 0.5975\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5902 - val_loss: 0.5971\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5906 - val_loss: 0.5968\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5900 - val_loss: 0.5966\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5895 - val_loss: 0.5967\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5888 - val_loss: 0.5960\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5890 - val_loss: 0.5958\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5893 - val_loss: 0.5953\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5888 - val_loss: 0.5957\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5881 - val_loss: 0.5947\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5875 - val_loss: 0.5947\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5869 - val_loss: 0.5940\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5872 - val_loss: 0.5939\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5864 - val_loss: 0.5932\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5874 - val_loss: 0.5926\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5864 - val_loss: 0.5924\n",
            "Epoch 55/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5866 - val_loss: 0.5921\n",
            "Epoch 56/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5860 - val_loss: 0.5916\n",
            "Epoch 57/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5838 - val_loss: 0.5915\n",
            "Epoch 58/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5849 - val_loss: 0.5911\n",
            "Epoch 59/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5842 - val_loss: 0.5908\n",
            "Epoch 60/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5840 - val_loss: 0.5909\n",
            "Epoch 61/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5829 - val_loss: 0.5900\n",
            "Epoch 62/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5841 - val_loss: 0.5896\n",
            "Epoch 63/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5819 - val_loss: 0.5892\n",
            "Epoch 64/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5830 - val_loss: 0.5894\n",
            "Epoch 65/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5826 - val_loss: 0.5888\n",
            "Epoch 66/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5824 - val_loss: 0.5889\n",
            "Epoch 67/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5818 - val_loss: 0.5887\n",
            "Epoch 68/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5824 - val_loss: 0.5889\n",
            "Epoch 69/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5808 - val_loss: 0.5886\n",
            "Epoch 70/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5821 - val_loss: 0.5881\n",
            "Epoch 71/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5813 - val_loss: 0.5883\n",
            "Epoch 72/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5809 - val_loss: 0.5896\n",
            "Epoch 73/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5832 - val_loss: 0.5886\n",
            "Epoch 74/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5809 - val_loss: 0.5879\n",
            "Epoch 75/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5818 - val_loss: 0.5884\n",
            "Epoch 76/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5814 - val_loss: 0.5883\n",
            "Epoch 77/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5821 - val_loss: 0.5919\n",
            "Epoch 78/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5854 - val_loss: 0.5908\n",
            "Epoch 79/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5836 - val_loss: 0.5892\n",
            "Epoch 80/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5825 - val_loss: 0.5888\n",
            "Epoch 81/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5835 - val_loss: 0.5878\n",
            "Epoch 82/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5846 - val_loss: 0.5907\n",
            "Epoch 83/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5844 - val_loss: 0.5890\n",
            "Epoch 84/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5833 - val_loss: 0.5890\n",
            "Epoch 85/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5841 - val_loss: 0.5888\n",
            "Epoch 86/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5827 - val_loss: 0.5885\n",
            "Epoch 87/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5821 - val_loss: 0.5878\n",
            "Epoch 88/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5826 - val_loss: 0.5877\n",
            "Epoch 89/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5817 - val_loss: 0.5870\n",
            "Epoch 90/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5819 - val_loss: 0.5874\n",
            "Epoch 91/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5814 - val_loss: 0.5892\n",
            "Epoch 92/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5827 - val_loss: 0.5877\n",
            "Epoch 93/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5812 - val_loss: 0.5875\n",
            "Epoch 94/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5803 - val_loss: 0.5875\n",
            "Epoch 95/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5805 - val_loss: 0.5877\n",
            "Epoch 96/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5795 - val_loss: 0.5866\n",
            "Epoch 97/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5811 - val_loss: 0.5870\n",
            "Epoch 98/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5822 - val_loss: 0.5874\n",
            "Epoch 99/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5816 - val_loss: 0.5868\n",
            "Epoch 100/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5804 - val_loss: 0.5876\n",
            "Epoch 101/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5804 - val_loss: 0.5866\n",
            "Epoch 102/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5805 - val_loss: 0.5861\n",
            "Epoch 103/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5789 - val_loss: 0.5857\n",
            "Epoch 104/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5789 - val_loss: 0.5855\n",
            "Epoch 105/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5794 - val_loss: 0.5854\n",
            "Epoch 106/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5789 - val_loss: 0.5851\n",
            "Epoch 107/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5779 - val_loss: 0.5864\n",
            "Epoch 108/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5795 - val_loss: 0.5852\n",
            "Epoch 109/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5777 - val_loss: 0.5847\n",
            "Epoch 110/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5788 - val_loss: 0.5850\n",
            "Epoch 111/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5785 - val_loss: 0.5912\n",
            "Epoch 112/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5831 - val_loss: 0.5875\n",
            "Epoch 113/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5808 - val_loss: 0.5870\n",
            "Epoch 114/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5788 - val_loss: 0.5857\n",
            "Epoch 115/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5777 - val_loss: 0.5846\n",
            "Epoch 116/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5775 - val_loss: 0.5842\n",
            "Epoch 117/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5767 - val_loss: 0.5838\n",
            "Epoch 118/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5775 - val_loss: 0.5833\n",
            "Epoch 119/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5766 - val_loss: 0.5836\n",
            "Epoch 120/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5772 - val_loss: 0.5836\n",
            "Epoch 121/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5774 - val_loss: 0.5831\n",
            "Epoch 122/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5773 - val_loss: 0.5829\n",
            "Epoch 123/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5761 - val_loss: 0.5827\n",
            "Epoch 124/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5762 - val_loss: 0.5831\n",
            "Epoch 125/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5774 - val_loss: 0.5839\n",
            "Epoch 126/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5767 - val_loss: 0.5830\n",
            "Epoch 127/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5767 - val_loss: 0.5826\n",
            "Epoch 128/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5753 - val_loss: 0.5825\n",
            "Epoch 129/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5765 - val_loss: 0.5822\n",
            "Epoch 130/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5748 - val_loss: 0.5818\n",
            "Epoch 131/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5757 - val_loss: 0.5822\n",
            "Epoch 132/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5766 - val_loss: 0.5827\n",
            "Epoch 133/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5747 - val_loss: 0.5821\n",
            "Epoch 134/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5744 - val_loss: 0.5815\n",
            "Epoch 135/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5758 - val_loss: 0.5834\n",
            "Epoch 136/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5770 - val_loss: 0.5828\n",
            "Epoch 137/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5756 - val_loss: 0.5824\n",
            "Epoch 138/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5768 - val_loss: 0.5818\n",
            "Epoch 139/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5753 - val_loss: 0.5816\n",
            "Epoch 140/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5745 - val_loss: 0.5812\n",
            "Epoch 141/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5741 - val_loss: 0.5806\n",
            "Epoch 142/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5742 - val_loss: 0.5813\n",
            "Epoch 143/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5744 - val_loss: 0.5810\n",
            "Epoch 144/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5747 - val_loss: 0.5809\n",
            "Epoch 145/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5736 - val_loss: 0.5817\n",
            "Epoch 146/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5737 - val_loss: 0.5812\n",
            "Epoch 147/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5744 - val_loss: 0.5823\n",
            "Epoch 148/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5748 - val_loss: 0.5816\n",
            "Epoch 149/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5749 - val_loss: 0.5808\n",
            "Epoch 150/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5732 - val_loss: 0.5811\n",
            "Epoch 151/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5731 - val_loss: 0.5807\n",
            "Epoch 152/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5738 - val_loss: 0.5806\n",
            "Epoch 153/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5735 - val_loss: 0.5804\n",
            "Epoch 154/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5735 - val_loss: 0.5803\n",
            "Epoch 155/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5720 - val_loss: 0.5799\n",
            "Epoch 156/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5726 - val_loss: 0.5807\n",
            "Epoch 157/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5741 - val_loss: 0.5823\n",
            "Epoch 158/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5743 - val_loss: 0.5811\n",
            "Epoch 159/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5734 - val_loss: 0.5806\n",
            "Epoch 160/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5739 - val_loss: 0.5807\n",
            "Epoch 161/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5740 - val_loss: 0.5802\n",
            "Epoch 162/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5725 - val_loss: 0.5803\n",
            "Epoch 163/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5729 - val_loss: 0.5803\n",
            "Epoch 164/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5731 - val_loss: 0.5804\n",
            "Epoch 165/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5715 - val_loss: 0.5795\n",
            "Epoch 166/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5728 - val_loss: 0.5799\n",
            "Epoch 167/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5725 - val_loss: 0.5791\n",
            "Epoch 168/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5724 - val_loss: 0.5791\n",
            "Epoch 169/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5723 - val_loss: 0.5791\n",
            "Epoch 170/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5716 - val_loss: 0.5790\n",
            "Epoch 171/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5716 - val_loss: 0.5819\n",
            "Epoch 172/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5731 - val_loss: 0.5806\n",
            "Epoch 173/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5720 - val_loss: 0.5813\n",
            "Epoch 174/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5735 - val_loss: 0.5805\n",
            "Epoch 175/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5730 - val_loss: 0.5799\n",
            "Epoch 176/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5746 - val_loss: 0.5840\n",
            "Epoch 177/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5760 - val_loss: 0.5825\n",
            "Epoch 178/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5745 - val_loss: 0.5815\n",
            "Epoch 179/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5734 - val_loss: 0.5806\n",
            "Epoch 180/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5738 - val_loss: 0.5804\n",
            "Epoch 181/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5720 - val_loss: 0.5799\n",
            "Epoch 182/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5719 - val_loss: 0.5795\n",
            "Epoch 183/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5722 - val_loss: 0.5800\n",
            "Epoch 184/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5727 - val_loss: 0.5798\n",
            "Epoch 185/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5715 - val_loss: 0.5793\n",
            "Epoch 186/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5712 - val_loss: 0.5794\n",
            "Epoch 187/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5728 - val_loss: 0.5797\n",
            "Epoch 188/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5721 - val_loss: 0.5806\n",
            "Epoch 189/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5726 - val_loss: 0.5801\n",
            "Epoch 190/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5732 - val_loss: 0.5801\n",
            "Epoch 191/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5724 - val_loss: 0.5793\n",
            "Epoch 192/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5711 - val_loss: 0.5790\n",
            "Epoch 193/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5714 - val_loss: 0.5801\n",
            "Epoch 194/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5726 - val_loss: 0.5796\n",
            "Epoch 195/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5717 - val_loss: 0.5794\n",
            "Epoch 196/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5703 - val_loss: 0.5791\n",
            "Epoch 197/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5713 - val_loss: 0.5790\n",
            "Epoch 198/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5706 - val_loss: 0.5786\n",
            "Epoch 199/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5699 - val_loss: 0.5785\n",
            "Epoch 200/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5706 - val_loss: 0.5783\n",
            "test auc = 0.7625899783968562 in cv = 3\n",
            "\n",
            " cv 3 finished for assist2017\n",
            "\n",
            "\n",
            " cv 4 starts for assist2017\n",
            "\n",
            "train data in /content/dirve/My Drive/dktt_light/data/assist2017-cv-train-4.csv is loaded\n",
            "test data in /content/dirve/My Drive/dktt_light/data/assist2017-cv-test-4.csv is loaded\n",
            "problem and skill encoders are created\n",
            "train and test data are cleaned\n",
            "train and test sequences are extracted\n",
            "100% 1368/1368 [00:00<00:00, 10917.99it/s]\n",
            "100% 341/341 [00:00<00:00, 11780.20it/s]\n",
            "train and test sequences are folded\n",
            "train and test inputs and targets are created\n",
            "problem skill mapping is created\n",
            "model is created\n",
            "model is compiled\n",
            "start fitting\n",
            "Epoch 1/200\n",
            "47/47 [==============================] - 7s 82ms/step - loss: 0.7552 - val_loss: 0.6547\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6558 - val_loss: 0.6506\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6531 - val_loss: 0.6485\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6504 - val_loss: 0.6456\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6476 - val_loss: 0.6424\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6420 - val_loss: 0.6382\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6379 - val_loss: 0.6325\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6309 - val_loss: 0.6260\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6247 - val_loss: 0.6209\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6192 - val_loss: 0.6165\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6145 - val_loss: 0.6129\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6104 - val_loss: 0.6104\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6077 - val_loss: 0.6096\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.6065 - val_loss: 0.6074\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6042 - val_loss: 0.6061\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6040 - val_loss: 0.6056\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6019 - val_loss: 0.6048\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6002 - val_loss: 0.6041\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.6005 - val_loss: 0.6033\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5988 - val_loss: 0.6035\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5988 - val_loss: 0.6028\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5973 - val_loss: 0.6020\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5971 - val_loss: 0.6027\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5959 - val_loss: 0.6015\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5969 - val_loss: 0.6007\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5965 - val_loss: 0.6006\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5955 - val_loss: 0.6005\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5948 - val_loss: 0.6002\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5947 - val_loss: 0.6000\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5941 - val_loss: 0.6008\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5939 - val_loss: 0.5995\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5932 - val_loss: 0.5991\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5913 - val_loss: 0.5986\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5927 - val_loss: 0.5986\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5921 - val_loss: 0.5990\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5913 - val_loss: 0.5979\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5917 - val_loss: 0.5979\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5901 - val_loss: 0.5976\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5902 - val_loss: 0.5968\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5900 - val_loss: 0.5967\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5889 - val_loss: 0.5962\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5895 - val_loss: 0.5962\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5887 - val_loss: 0.5954\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5884 - val_loss: 0.5951\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5875 - val_loss: 0.5945\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5880 - val_loss: 0.5942\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5866 - val_loss: 0.5938\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5871 - val_loss: 0.5933\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5857 - val_loss: 0.5928\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5853 - val_loss: 0.5925\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5852 - val_loss: 0.5923\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5849 - val_loss: 0.5919\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5854 - val_loss: 0.5913\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5834 - val_loss: 0.5907\n",
            "Epoch 55/200\n",
            "47/47 [==============================] - 3s 71ms/step - loss: 0.5834 - val_loss: 0.5910\n",
            "Epoch 56/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5822 - val_loss: 0.5905\n",
            "Epoch 57/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5831 - val_loss: 0.5906\n",
            "Epoch 58/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5824 - val_loss: 0.5899\n",
            "Epoch 59/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5818 - val_loss: 0.5896\n",
            "Epoch 60/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5810 - val_loss: 0.5886\n",
            "Epoch 61/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5817 - val_loss: 0.5889\n",
            "Epoch 62/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5819 - val_loss: 0.5881\n",
            "Epoch 63/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5807 - val_loss: 0.5877\n",
            "Epoch 64/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5807 - val_loss: 0.5874\n",
            "Epoch 65/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5787 - val_loss: 0.5872\n",
            "Epoch 66/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5807 - val_loss: 0.5868\n",
            "Epoch 67/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5793 - val_loss: 0.5866\n",
            "Epoch 68/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5790 - val_loss: 0.5868\n",
            "Epoch 69/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5789 - val_loss: 0.5858\n",
            "Epoch 70/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5780 - val_loss: 0.5861\n",
            "Epoch 71/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5782 - val_loss: 0.5852\n",
            "Epoch 72/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5778 - val_loss: 0.5849\n",
            "Epoch 73/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5774 - val_loss: 0.5847\n",
            "Epoch 74/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5770 - val_loss: 0.5846\n",
            "Epoch 75/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5760 - val_loss: 0.5843\n",
            "Epoch 76/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5770 - val_loss: 0.5842\n",
            "Epoch 77/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5762 - val_loss: 0.5837\n",
            "Epoch 78/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5760 - val_loss: 0.5836\n",
            "Epoch 79/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5767 - val_loss: 0.5832\n",
            "Epoch 80/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5753 - val_loss: 0.5828\n",
            "Epoch 81/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5761 - val_loss: 0.5830\n",
            "Epoch 82/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5756 - val_loss: 0.5826\n",
            "Epoch 83/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5740 - val_loss: 0.5827\n",
            "Epoch 84/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5737 - val_loss: 0.5828\n",
            "Epoch 85/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5737 - val_loss: 0.5822\n",
            "Epoch 86/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5736 - val_loss: 0.5819\n",
            "Epoch 87/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5738 - val_loss: 0.5814\n",
            "Epoch 88/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5734 - val_loss: 0.5817\n",
            "Epoch 89/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5739 - val_loss: 0.5817\n",
            "Epoch 90/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5726 - val_loss: 0.5814\n",
            "Epoch 91/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5732 - val_loss: 0.5808\n",
            "Epoch 92/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5736 - val_loss: 0.5808\n",
            "Epoch 93/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5719 - val_loss: 0.5805\n",
            "Epoch 94/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5724 - val_loss: 0.5802\n",
            "Epoch 95/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5724 - val_loss: 0.5801\n",
            "Epoch 96/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5721 - val_loss: 0.5806\n",
            "Epoch 97/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5705 - val_loss: 0.5798\n",
            "Epoch 98/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5715 - val_loss: 0.5801\n",
            "Epoch 99/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5713 - val_loss: 0.5800\n",
            "Epoch 100/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5699 - val_loss: 0.5795\n",
            "Epoch 101/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5714 - val_loss: 0.5794\n",
            "Epoch 102/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5697 - val_loss: 0.5789\n",
            "Epoch 103/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5696 - val_loss: 0.5788\n",
            "Epoch 104/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5703 - val_loss: 0.5788\n",
            "Epoch 105/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5698 - val_loss: 0.5790\n",
            "Epoch 106/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5703 - val_loss: 0.5784\n",
            "Epoch 107/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5696 - val_loss: 0.5782\n",
            "Epoch 108/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5696 - val_loss: 0.5784\n",
            "Epoch 109/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5691 - val_loss: 0.5777\n",
            "Epoch 110/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5681 - val_loss: 0.5783\n",
            "Epoch 111/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5689 - val_loss: 0.5775\n",
            "Epoch 112/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5693 - val_loss: 0.5772\n",
            "Epoch 113/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5684 - val_loss: 0.5769\n",
            "Epoch 114/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5685 - val_loss: 0.5770\n",
            "Epoch 115/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5677 - val_loss: 0.5770\n",
            "Epoch 116/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5674 - val_loss: 0.5768\n",
            "Epoch 117/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5677 - val_loss: 0.5772\n",
            "Epoch 118/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5674 - val_loss: 0.5764\n",
            "Epoch 119/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5676 - val_loss: 0.5761\n",
            "Epoch 120/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5671 - val_loss: 0.5754\n",
            "Epoch 121/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5661 - val_loss: 0.5749\n",
            "Epoch 122/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5671 - val_loss: 0.5747\n",
            "Epoch 123/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5674 - val_loss: 0.5745\n",
            "Epoch 124/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5665 - val_loss: 0.5744\n",
            "Epoch 125/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5669 - val_loss: 0.5742\n",
            "Epoch 126/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5674 - val_loss: 0.5739\n",
            "Epoch 127/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5665 - val_loss: 0.5738\n",
            "Epoch 128/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5674 - val_loss: 0.5741\n",
            "Epoch 129/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5661 - val_loss: 0.5741\n",
            "Epoch 130/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5658 - val_loss: 0.5740\n",
            "Epoch 131/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5657 - val_loss: 0.5738\n",
            "Epoch 132/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5665 - val_loss: 0.5739\n",
            "Epoch 133/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5656 - val_loss: 0.5737\n",
            "Epoch 134/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5665 - val_loss: 0.5730\n",
            "Epoch 135/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5643 - val_loss: 0.5734\n",
            "Epoch 136/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5656 - val_loss: 0.5731\n",
            "Epoch 137/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5657 - val_loss: 0.5730\n",
            "Epoch 138/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5652 - val_loss: 0.5726\n",
            "Epoch 139/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5639 - val_loss: 0.5727\n",
            "Epoch 140/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5648 - val_loss: 0.5730\n",
            "Epoch 141/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5649 - val_loss: 0.5728\n",
            "Epoch 142/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5653 - val_loss: 0.5723\n",
            "Epoch 143/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5639 - val_loss: 0.5719\n",
            "Epoch 144/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5638 - val_loss: 0.5721\n",
            "Epoch 145/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5650 - val_loss: 0.5722\n",
            "Epoch 146/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5639 - val_loss: 0.5719\n",
            "Epoch 147/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5629 - val_loss: 0.5724\n",
            "Epoch 148/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5633 - val_loss: 0.5717\n",
            "Epoch 149/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5635 - val_loss: 0.5717\n",
            "Epoch 150/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5620 - val_loss: 0.5717\n",
            "Epoch 151/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5633 - val_loss: 0.5727\n",
            "Epoch 152/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5628 - val_loss: 0.5718\n",
            "Epoch 153/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5629 - val_loss: 0.5718\n",
            "Epoch 154/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5630 - val_loss: 0.5714\n",
            "Epoch 155/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5617 - val_loss: 0.5709\n",
            "Epoch 156/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5620 - val_loss: 0.5717\n",
            "Epoch 157/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5633 - val_loss: 0.5719\n",
            "Epoch 158/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5626 - val_loss: 0.5713\n",
            "Epoch 159/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5619 - val_loss: 0.5712\n",
            "Epoch 160/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5618 - val_loss: 0.5711\n",
            "Epoch 161/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5629 - val_loss: 0.5703\n",
            "Epoch 162/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5599 - val_loss: 0.5712\n",
            "Epoch 163/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5605 - val_loss: 0.5703\n",
            "Epoch 164/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5610 - val_loss: 0.5711\n",
            "Epoch 165/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5610 - val_loss: 0.5702\n",
            "Epoch 166/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5599 - val_loss: 0.5698\n",
            "Epoch 167/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5605 - val_loss: 0.5702\n",
            "Epoch 168/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5609 - val_loss: 0.5699\n",
            "Epoch 169/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5611 - val_loss: 0.5702\n",
            "Epoch 170/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5604 - val_loss: 0.5704\n",
            "Epoch 171/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5597 - val_loss: 0.5700\n",
            "Epoch 172/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5597 - val_loss: 0.5697\n",
            "Epoch 173/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5600 - val_loss: 0.5700\n",
            "Epoch 174/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5605 - val_loss: 0.5696\n",
            "Epoch 175/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5590 - val_loss: 0.5694\n",
            "Epoch 176/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5599 - val_loss: 0.5702\n",
            "Epoch 177/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5599 - val_loss: 0.5694\n",
            "Epoch 178/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5589 - val_loss: 0.5699\n",
            "Epoch 179/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5583 - val_loss: 0.5701\n",
            "Epoch 180/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5596 - val_loss: 0.5694\n",
            "Epoch 181/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5589 - val_loss: 0.5692\n",
            "Epoch 182/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5584 - val_loss: 0.5699\n",
            "Epoch 183/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5583 - val_loss: 0.5695\n",
            "Epoch 184/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5594 - val_loss: 0.5692\n",
            "Epoch 185/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5586 - val_loss: 0.5694\n",
            "Epoch 186/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5591 - val_loss: 0.5710\n",
            "Epoch 187/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5591 - val_loss: 0.5691\n",
            "Epoch 188/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5602 - val_loss: 0.5691\n",
            "Epoch 189/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5589 - val_loss: 0.5704\n",
            "Epoch 190/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5580 - val_loss: 0.5687\n",
            "Epoch 191/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5579 - val_loss: 0.5689\n",
            "Epoch 192/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5590 - val_loss: 0.5687\n",
            "Epoch 193/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5569 - val_loss: 0.5692\n",
            "Epoch 194/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5569 - val_loss: 0.5692\n",
            "Epoch 195/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5574 - val_loss: 0.5692\n",
            "Epoch 196/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5574 - val_loss: 0.5685\n",
            "Epoch 197/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5569 - val_loss: 0.5690\n",
            "Epoch 198/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5577 - val_loss: 0.5696\n",
            "Epoch 199/200\n",
            "47/47 [==============================] - 3s 70ms/step - loss: 0.5582 - val_loss: 0.5687\n",
            "Epoch 200/200\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.5584 - val_loss: 0.5687\n",
            "test auc = 0.7839042717008293 in cv = 4\n",
            "\n",
            " cv 4 finished for assist2017\n",
            "\n",
            "Model: \"dktt_light\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_shared_weights_4 ( multiple                  1703208   \n",
            "_________________________________________________________________\n",
            "encoder_stack (EncoderStack) multiple                  33252     \n",
            "_________________________________________________________________\n",
            "decoder_stack (DecoderStack) multiple                  0         \n",
            "=================================================================\n",
            "Total params: 1,736,460\n",
            "Trainable params: 1,736,460\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "average test auc for assist2017 is 0.7775962864239654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrFGenUqbs_q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}